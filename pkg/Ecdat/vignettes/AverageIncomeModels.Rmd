---
title: "Economic impact of presidents and war"
author: "Spencer Graves and Jouni Helske"
date: "`r Sys.Date()`"
output:
      rmarkdown::html_vignette:
        fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Average Income Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}{inputenc}
---
```{r setup, include = FALSE, cache = FALSE}
library(RefManageR)
bibFile <- system.file("Bib", "biblatexExamples.bib", 
                           package = "RefManageR")
bib <- ReadBib(bibFile, check = FALSE)
bibF2 <- "AvgInc.bib"
bib2 <- ReadBib(bibF2) 
BibOptions(check.entries = FALSE, style = "markdown", cite.style = "authoryear",
           bib.style = "numeric")
```

# Abstract 

This vignette illustrates the use of the [KFAS](https://rweb.crmda.ku.edu/cran/web/packages/KFAS/KFAS.pdf) package for R to evaluate the claim that [World War II (WW II)](https://en.wikipedia.org/wiki/Great_Depression#World_War_II_and_recovery), not [Franklin Roosevelt (FDR)](https://en.wikipedia.org/wiki/Franklin_D._Roosevelt), ended the [Great Depression](https://en.wikipedia.org/wiki/Great_Depression).  This is the dominant view of the evolution of the US economy between 1933 and 1945.  It is supported by our review of the available unemployment data but superficially contradicted by our naive analyses of average annual income in the US ([real US Gross Domestic Product (GDP) per capita](https://en.wikipedia.org/wiki/Real_gross_domestic_product), 1790-2014, from [MeasuringWorth](http://measuringworth.com/)): First, other wars have not been accompanied by such obvious growth spurts.  Second, FDR's economic performance even without World War II seems unmatched by any other U.S. president.  This document describes alternative attempts to quantify the economic impact of wars separate from that of the administration ("president").  This includes a detailed discussion and comparison of alternative models of economic growth and how [KFAS](https://rweb.crmda.ku.edu/cran/web/packages/KFAS/KFAS.pdf) was used to fit them.  We have four conclusions:  The models we fit failed to find a signficant effect of war on real GDP per capita but did find that the performance of the U.S. economy under the Hoover and FDR administrations was dramatically different from that for any other presidency.  Second, our models provide another perspective on [Okun's law](https://en.wikipedia.org/wiki/Okun%27s_law) relating the changes in unemployment and the rate of economic growth.  Third, these conclusions must be considered tentative, because these models do not consider other variables that might impact economic growth and unemployment. Fourth, more generally, KFAS provides a powerful set of tools for modeling extensions to the present analysis, e.g., mixing data from multiple sources such as joint models of GDP per capita with unemployment and mixing annual and quarterly data.   

# Introduction  

The Legacy of the [New Deal](https://en.wikipedia.org/wiki/New_Deal) and the [Great Depression](https://en.wikipedia.org/wiki/Great_Depression) still carry profound implications for the current economic policies of the world's most economically advanced countries.  `r Citet(bib2, "Horowitz2011")` recently claimed that Hoover had more aggressive deficit spending and public works programs than [Franklin Roosevelt](https://en.wikipedia.org/wiki/Franklin_D._Roosevelt), and far from contributing to the recovery, these programs actually made the economy worse.  He concluded that "The persistence of the Hoover myth continues to justify the counterproductive policies of the Obama administration and thereby prevents markets from generating the economic recovery of which they are fully capable." However, Horowitz's report discusses no model fits, includes no tables and plots only "real federal spending" from 1929 to 1934.    

`r Citet(bib2, "McChesney2014")` said, "In earlier eras it had been assumed that there was an economic 'guns and butter' tradeoff, and that military spending had to occur at the expense of other sectors of the economy.  However, one of the lessons of the economic expansion in Nazi Germany, followed by the experience of the United States itself in arming for the Second World War, was that big increases in military spending could act as huge stimulants to the economy." Other research identified alternatives that would reportedly produce more jobs than military spending:  Tax cuts for household consumption and increased spending on clean energy, health care and education would produce 27, 47, 69 and 151 percent more jobs, respectively, than military spending, according to `r Citet(bib2, "Pollin2009")`.  

Beyond this, the work of [Milton Friedman](https://en.wikipedia.org/wiki/Milton_Friedman) and others suggests that modeling like this should also consider [inflation](https://en.wikipedia.org/wiki/Inflation) and [unemployment](https://en.wikipedia.org/wiki/Unemployment);  we consider unemployment but not inflation.    

Whatever the specific cause, the growth of the U.S. economy under [FDR](https://en.wikipedia.org/wiki/Franklin_D._Roosevelt) before the war was not matched by that of any other president (not counting the negative record of [Herbert Hoover](https://en.wikipedia.org/wiki/Herbert_Hoover)).  This document describes alternative attempts to quantify the economic impact of wars separate from that of the administration ("president").  This includes a detailed discussion and comparison of alternative models of economic growth and how [KFAS](https://rweb.crmda.ku.edu/cran/web/packages/KFAS/KFAS.pdf) was used to fit them.  

The best of the models we fit include a "Presidency" effect.  We found a "war" effect for unemployment but not directly for real GDP per capita.  However, these conclusions must be considered tentative, pending further research using other data and possibly other ways of modeling the macroeconomic impact of war.  

# Initial Plots

We start by plotting the [MeasuringWorth](http://measuringworth.com/) estimates of average annual income in the US (adjusted for inflation) from 1790 to 2014:

```{r,fig.cap = "real US GDP per capita (thousands of 2009 $)"}
suppressMessages(library(Ecdat))
plot(realGDPperCapita/1000~Year, USGDPpresidents)     
```     

This plot could be changed in many ways to make it more informative. First, this [data.frame](https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html) covers many years for which we have no GDP data.  Let's start by checking missing data:  

```{r}
which(GDPna <- is.na(USGDPpresidents$realGDPperCapita))
```

The only NAs are the first 33 observations.  Those contain data on other variables for years prior to 1790.  We won't use any of that data for this analysis.  Let's discard it:  

```{r}
GDP. <- USGDPpresidents[!GDPna,]
```

Let's try that plot again, this time on a log scale with improved labeling:  

```{r,fig.cap = "real US GDP per capita (thousands of 2009 $)"}
plot(realGDPperCapita/1000~Year, GDP., log='y', type='l',
     ylab='thousands of 2009 dollars', las=1, 
     main='Real US GDP per capita')     
```     

This plot suggests relatively steady growth from 1790 to 2014 with the exception of a dramatic rise roughly two thirds of the way through the series preceded and followed by declines.  

The president is identified in an [ordered factor](https://stat.ethz.ch/R-manual/R-devel/library/base/html/factor.html), "executive", giving the names of the chief executive (president since 1790).  We need to drop the unused levels from the colonial period:  

```{r}
GDP.$executive <- ordered(GDP.$executive)
levels(GDP.$executive)
```

This [data.frame](https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html) includes three variables for war.  The first is an [ordered factor](https://stat.ethz.ch/R-manual/R-devel/library/base/html/factor.html).  We need to drop the unused levels of "war", as we just did for "executive":  

```{r}
GDP.$war <- ordered(GDP.$war)
levels(GDP.$war)
```

The next war variable is the number of "battleDeaths" for each war apportioned by the number of days in each year between the official start and end of each war.  However, it hardly makes sense to use this directly as a measure of the impact of the war on the economy, as the nation grew from 3.9 million souls in 1790 to 319 million in 2014.  Instead, we use battle deaths per million population:  

```{r,fig.cap = "Battle deaths per million population"}
plot(battleDeathsPMP~Year, GDP., type='l',
     ylab='battle deaths per million pop', las=1, 
     main='Battle deaths during war')     
```     

Wars involving fewer than 10 battle deaths per million US population per year are not included.  No war since Vietnam has reached that threshold.  This explains why the 2001-2014 [War in Afghanistan](https://en.wikipedia.org/wiki/War_in_Afghanistan_(2001%E2%80%9314)) and the 2003-2011 [Iraq war](https://en.wikipedia.org/wiki/Iraq_War) do not appear here:  As noted in the help page for USGDPpresidents, the two together averaged fewer than 3 battle deaths per year per million population.

This document first adds annotations to the above plot of realGDPperCapita then considers a series of models that estimate a base growth rate separate from other potential explanatory variables such as the administration (the president) and wars.  Readers interested in the results are encouraged to focus on the plots and tables, skipping the math and software.  

# Graphical analysis 

We want a simple computation that will identify the exceptional period in the above plot.  First, let's compute the range:  

```{r}
head(GDP., 1)
tail(GDP., 1)
range(GDP.$realGDPperCapita)
```

It's common to work with log(dollars) rather than dollars directly.  This is obvious to many who work with finance but foreign to many others.  For the latter group, it's worth noting that a $500 drop in annual income would have been catastrophic in 1790, representing almost half the average income at the time.  However a similar $500 drop around 2014 would be hardly noticeable, being just under 1 percent of the 2014 average income.  Moreover, a small change in logarithms can be interpreted as percentage, since log(1+x) is approximately x when x is small (using [natural logarithms](https://en.wikipedia.org/wiki/Natural_logarithm)).  

We start looking for this exceptional period by computing the differences in log(real GDP per capita):  

```{r}
difGDP <- diff(log(GDP.$realGDPperCapita))
```

A run up or down *ends* where difGDP changes sign from one year to the next:  

```{r}
chgSgn <- c(TRUE, (head(difGDP, -1)*tail(difGDP, -1))<0)
```

We convert this logical vector to an index numbering the runs using [cumsum](https://stat.ethz.ch/R-manual/R-devel/library/base/html/cumsum.html):  


```{r}
GDPrun <- cumsum(chgSgn)
```

We use [tapply](https://stat.ethz.ch/R-manual/R-devel/library/base/html/tapply.html) to identify the beginning and end of each run and to compute run length and total and average growth:  

```{r}
yr0 <- head(GDP.$Year, -1)
runStart <- tapply(yr0, GDPrun, min)
yr1 <- tail(GDP.$Year, -1)
runEnd <- tapply(yr1, GDPrun, max)
N <- nrow(GDP.)
runLength <- tapply(rep(1, N-1), GDPrun, sum)
totGrowth <- tapply(difGDP, GDPrun, sum)
avgGrowth <- tapply(difGDP, GDPrun, mean)
```

We organize these numbers into a [data.frame](https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html) for convenience:  

```{r}
str(GDPruns <- data.frame(runStart=runStart, 
      runEnd=runEnd, runLength=runLength, 
      totalGrowth=totGrowth, meanGrowth=avgGrowth))
```

To focus on the potentially most interesting periods, we select the runs with average growth exceeding 0.08 (positive or negative):  

```{r}
GDPruns[abs(GDPruns$meanGrowth)>0.08,]
```

This gives us six runs, three of which occur in the period that jumps off the above plot at us:  1929-1933, 1933-1937, and 1938-1944.  The first period is the presidency of [Herbert Hoover](https://en.wikipedia.org/wiki/Herbert_Hoover), and the last two encompass the [FDR](https://en.wikipedia.org/wiki/Franklin_D._Roosevelt) years of the [Great Depression](https://en.wikipedia.org/wiki/Great_Depression) and [World War II](https://en.wikipedia.org/wiki/World_War_II).  (The break in the middle is the "[Recession of 1937-38](https://en.wikipedia.org/wiki/Recession_of_1937%E2%80%9338)", which convinced FDR to restore the high levels of government spending that seemed to make the difference between the disaster of 1929-33 and the growth of 1934-36.  If we lower the threshold to 0.06, we get 10 runs, the first of which is 1861-1863 at the beginning of the [American Civil War](https://en.wikipedia.org/wiki/American_Civil_War).  The last is the post WW II recession.  The others do not appear to be related to presidents or wars.)  

We label these points on the above plot:  
     
```{r,fig.cap = "Presidents & exceptional change in GDP"}
plot(realGDPperCapita/1000~Year, GDP., type='l', log='y', 
     main=paste0('US average annual income\n', 
                 '(GDP per capita)'), 
     ylab='thousands of 2009 dollars', las=1)     
abline(v=c(1929, 1933, 1945), lty='dashed', col='grey')
text(1930, 2.5, "Hoover", srt=90, cex=0.9)
text(1939.5, 30, 'FDR', srt=90, cex=1.1, col='blue')
```

We also want to label the wars on the plot.  Since we'll want war labels on other plots, and since we used multiple lines of code to do it, we'll create a function to support this:  

```{r,fig.cap = "Function to plot presidents and wars"}
plotPresWars <- function(x, Data, ..., 
     yHoover=0.8, yFDR=2, yWar=seq(1.7, by=-.1, len=9), 
     cex.war=0.67){
  X <- eval(substitute(x), Data)
  plot(X, ...)
  abline(v=c(1929, 1933, 1945), lty='dashed')
  usr <- par('usr')
  Hy <- (usr[3]+yHoover*diff(usr[3:4]))
  if(par('ylog'))Hy <- exp(Hy)
  text(1930, Hy, 'Hoover', srt=90, cex=.9, xpd=NA)
  Ry <- (usr[3]+yFDR*diff(usr[3:4]))
  if(par('ylog'))Ry <- exp(Ry)
  text(1939, Ry, 'FDR', srt=90, cex=1.1, col='blue', xpd=NA)
  yrMid <- mean(usr[1:2])
  dyr <- diff(usr[1:2])
  y. <- seq(usr[3], usr[4], len=5)
  dy <- diff(y.[c(2,4)])
  y2.5 <- mean(y.[c(2,3)])
  wars <- levels(Data$war)
  nWars <- length(wars)
  for(i in 2:nWars){
    w <- wars[i]
    sel <- (Data$war==w)
    yrs <- range(Data$Year[sel])
    abline(v=yrs, lty='dotted', col='grey')
    yr. <- mean(yrs)
    wy <- (y2.5 + yWar[i-1]*dy)
    if(par('ylog'))wy <- exp(wy)
    text(yr., wy, w, srt=90, col='red', cex=cex.war, 
         xpd=NA)
  }
  invisible("done")
}

plotPresWars(realGDPperCapita/1000, GDP., log='y', 
             main=paste0('US average annual income\n', 
                         '(GDP per capita)'), 
             ylab='thousands of 2009 dollars', las=1) 
```

This plot has problems.  Most importantly, the horizontal axis is labeled "Index" not "Year".  We can fix that by adding "Year" as the first argument to the call to [plot](https://stat.ethz.ch/R-manual/R-devel/library/graphics/html/plot.html).  A less obvious ways is to convert "realGDPperCapita" to an object of class [ts](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/ts.html):  

```{r,fig.cap = "Presidents, wars & change in GDP"}
GDP <- GDP.
GDP$realGDPperCapita <- ts(GDP$realGDPperCapita, 
                             GDP$Year[1])
plotPresWars(realGDPperCapita/1000, GDP, log='y', 
             main=paste0('US average annual income\n', 
                         '(GDP per capita)'), 
             ylab='thousands of 2009 dollars', las=1) 
```

The rest of this vignette describes various models of economic growth that include especially the impact of changes of administration and wars.  First we outline our basic approach to modeling these kinds of data.  

Let's try the same thing for unemployment:  

```{r,fig.cap = "Presidents, wars & unemployment"}
GDP$unemployment <- ts(GDP$unemployment, 
                             GDP$Year[1])
plotPresWars(unemployment, GDP, 
             main=paste0('US average annual income\n', 
                         '(GDP per capita)'), 
             ylab='thousands of 2009 dollars', las=1) 
```


# Bayesian sequential updating:  overview  

The models used here are all state space models, which we discuss in general here, giving specific examples later.  State space modeling is also known as Kalman (Kalman filtering, Kalman smoothing), and dynamic (linear) modeling.  For present purposes, we use the [KFAS](https://rweb.crmda.ku.edu/cran/web/packages/KFAS/KFAS.pdf) package, though many other R packages provide some support for this class of models.  

The theory behind these models can be described in terms of a 3-step Bayesian updating cycle to add new observations to a probability distribution summarizing the available knowledge about the state of the system under study `r AutoCite(bib2, "Graves07")`:

  1.  Receive and store new data.  
  
  1.  Create a prior distribution for the new data by modifying the posterior computed after the last observation to allow for possible changes in state in the time between the last and current observations.    
  
  1.  Combine the new data with the prior to produce a posterior distribution of the state.  
  
In the present discussion, the system under study is the US economy at various times, which we will summarize in a vector of one or more numbers that represent the state or condition of the economy at a particular point in time.  (The term "state" in "state space" refers to this type of representation.)  The data will be annual observations on real US GDP per capita (realGDPperCapita).  

The first model of this type discussed here considers univariate observations $y_t$ = log(real GDP per capita) on a hidden univariate state $\alpha_t$, which represents the portion of the annual number that persists.  In other words, the differences between the observations and predictions based on the hidden state are assumed to be uncorrelated across time;  any serial correlation in $y_t$ is assumed to be due to the hidden state,  $\alpha_t$.  

The general upward trend in the above plots of real GDP per capita indicate that a model with a univariate state will not fit very well. We use it to fix ideas and to serve as a basis for evaluating the importance of estimating the growth rate at time $t$ separate from the level -- and for evaluating the general utility of this approach to modeling time series.  

With univariate observations on a univariate state, the result is almost a traditional [exponentially weighted moving average (EWMA)](https://en.wikipedia.org/wiki/Exponential_smoothing), except that the weight on the last observation is adjusted with each observation consistent with the Bayesian sequential updating cycle outlined above.  In this case, this weight converges to an asymptote determined by the ratio of the migration and noise variances `r AutoCite(bib2, "Graves02")`. 
In the more general [Kalman filtering](https://en.wikipedia.org/wiki/Kalman_filter) terminology, the weight on the last observation (or the weight on the deviation of that observation from prediction) is called the Kalman gain.  Bayesian sequential updating produces a varying Kalman gain, though in many applications the Kalman gain converges to a constant.  Before fitting any model, we first describe the general [KFAS](https://rweb.crmda.ku.edu/cran/web/packages/KFAS/KFAS.pdf) model and show how the Bayesian EWMA described above is a special case.  This formulation allows the system to vary over time even to the extent of supporting asynchronous observations on different variables at irregular points in time.  

The next generalization beyond an EWMA is [double exponential smoothing](https://en.wikipedia.org/wiki/Exponential_smoothing#Double_exponential_smoothing):  It has a two-dimensional state vector with the first dimension being the level and the second being the rate of growth.  The plots above suggests that double exponential smoothing might work relatively well for log(realGDPperCapita) except for 1929-1947.  To model that period, we consider various ways of modeling presidents and wars.  

In the following, we shall consider several different though related models:  

 || Response | Model 
-:|:--------:|:---------------------------------------
1 | GDP/cap | EWMA1: Standard Bayesian EWMA
2 | GDP/cap | EWMA2: double EWMA 
3 | GDP/cap | EWMA2pres1: EWMA2 allowing slope to change only between presidents  
4 | GDP/cap | EWMA2pres2: EWMA2 estimating mean slope and no continuity between 
5 | GDP/cap | EWMA2pres3: EWMA2 with an adjustment for each president 
 | 
6 | GDP/cap | EWMA2war0: EWMA2 with fixed effect of war 
7 | GDP/cap | EWMA2war1: EWMA2 with random effect of war 
8 | GDP/cap | EWMA2war2: EWMA2 with variance effect for war
9 | unemp | uEWMA2: double EWMA 
10 | GDP/cap & unemp | oEWMA2: double EWMA 
11 | GDP/cap & unemp | oEWMA2pres: double EWMA with a president effect
12 | GDP/cap & unemp | oEWMA2war: double EWMA with a war effect 
13 | GDP/cap & unemp | oEWMA2pw: double EWMA modeling both president and war 

# 1.  The simplest Kalman Filter:  an Exponentially Weighted Moving Average (EWMA)

Consider a univariate noisy measurement, $y_t$, of a univariate state, $\alpha_t$:

$$y_t = \alpha_t + \epsilon_t$$

where the state, $\alpha_t$, follows a random walk:  

$$\alpha_{t+1} = \alpha_t + \eta_t.$$

In this model, we assume that observation error, $\epsilon_t$, and the random migration, $\eta_t$, are normally distributed with mean 0 and variance, $H$ and $Q$, respectively, and the initial state $\alpha_1$ is normal with mean $a_1$ and variance $P_1$.  We sometimes write $a_1$ and $P_1$ as $a_{1|0}$ and $P_{1|0}$ to make it clear that these are the prior mean and variance of $\alpha_1$ before $y_1$ is available (using the conditional subscript notation, following, e.g., `r Citet(bib2, "Harvey")`).  We may also use $a_{t|t}$ and $P_{t|t}$ to denote the posterior mean and variance given $D_t = \{y_t, y_{t-1}, ...\}$.  The prior distribution for $\alpha_t$ given $D_{t-1}$ and the posterior for $\alpha_t$ given $D_t$ will be computed recursively. (See `r Citet(bib2, "DurbinKoopman2")` for more detail on this model.)

These equations are called the measurement and state transition equations, respectively.  

We will estimate $H$ and $Q$ to maximize the likelihood.  We will also estimate the series $\alpha_t$ conditional on these estimates $H$, $Q$, $a_1$ and $P_1$.  

With this notation, we can provide more details in discussing the 3-step Bayesian sequential updating process outlined above: 

  1.  A new observation, $y_t$, arrives.  
  
  1.  The prior distribution $f(\alpha_t | D_{t-1})$ is computed from the previous posterior $f(\alpha_{t-1} | D_{t-1})$, where $D_{t-1}$ is all the information available prior to the arrival of $y_t$;  for $t$ = 0, this is already assumed as $\alpha_1 \tilde\ N(a_{1|0}, P_{1|0})$.  Otherwise, we have by recursion that the posterior for $(\alpha_{t-1} | D_{t-1})$ is $N(a_{t-1|t-1}, P_{t-1|t-1})$.  From this using a linear state transition equation, we get that the next prior $(\alpha_t | D_{t-1})$ is $N(a_{t|t-1}, P_{t|t-1})$.  In particular, the state transition equation above gives us $a_{t|t-1} = a_{t-1|t-1}$ and $P_{t|t-1} = P_{t-1|t-1} + Q.$  (The double subscripts help clarify the math, which can be confusing otherwise.)  

  1.  Bayes' theorem is then used to update this prior to incorporate the information in the new observation.  This converts $f(\alpha_t | D_{t-1})$ into $f(\alpha_t | D_t)$.    
  
The distribution of the state vector $\alpha_t$ is governed by certain hyperparameters, suppressed in the notation $f(\alpha_t | D_t)$.  These hyperparameters are estimated by maximum likelihood. 

# KFAS package for Kalman Filtering and Smoothing

State space modeling with the [KFAS](https://rweb.crmda.ku.edu/cran/web/packages/KFAS/KFAS.pdf) package assumes the following generalization of the above measurement and state transition equations:  

$$y_t = Z_t \alpha_t + \epsilon_t$$

$$\alpha_{t+1} = T_t \alpha_t + R_t \eta_t.$$

where $\epsilon_t \tilde\ N(0, H_t)$, $\eta_t \tilde\ N(0, Q_t)$ and $\alpha_1 \tilde\ N(a_1, P_1)$, independent of each other.  In this, $y_t$ is a $p$-vector (where $p$ may actually vary with $t$), $\alpha_t$ is $m$-dimensional, and $\eta_t$ has dimension $k$.  (See `r Citet(bib2, "DurbinKoopman")` for more detail on this model.)   

In all the models considered here, $y_t$ is log(realGDPperCapita). The dimensionality of $\alpha_t$ will vary, but the first component will always be the level.  Thus, $Z_t$ will be a row vector with 1 in the first position and 0 elsewhere. This will force $Q_t$, $T_t$, and $P_1$ to change between models.  In addition, some models have diffuse initialization for the state vector.  These are specified by a model component $P_{1,\infty}$;  see `r Citet(bib2, "KFASarticle")` or [SSmodel](http://rpackages.ianhowson.com/cran/KFAS/man/logLik.SSModel.html).  And the different models require estimating different parameters.  These pieces are summarized in the following table:  

 || Model | state vector components | time varying components | P1 | P1inf | parameters to estimate 
-:|:--------------------|:---------|:------:|:---:|:---:|:--------------
1 | EWMA1: Standard Bayesian EWMA | 1:level | | 0 | 1 | 2:lnQ, lnH
2 | EWMA2: double EWMA | 2:level, slope | | 0 | diag(2) | 3:lnQ.lvl, lnQ.slope, lnH
3 | EWMA2pres1: EWMA2 allowing slope to change only between presidents | 2:level, slope | Q | 0 | diag(2) | 3:lnQ.lvl, lnQ.slope, lnH 
4 | EWMA2pres2: EWMA2 estimating mean slope and no continuity between presidents | 3:level, slope, a1.slope | Q, T | diag(c(0, NA, 0)) | diag(c(1, 0, 0)) | 4:a1.slope, lnQ.lvl, lnQ.slope, lnH
5 | EWMA2pres3: EWMA2 with an adjustment for each president | 3:level, slope, pres3 | Q, T | diag(c(0, 0, NA) | diag(c(1, 1, 0)) | 4:lnQ.lvl, lnQ.slope, lnQ.pres3, lnH 
 | | | | | | | 
6 | EWMA2war0: EWMA2 with fixed effect of war | 4:level, slope, war, deaths | T | 0 | diag(4) | 3:lnQ.lvl, lnQ.slope, lnH
7 | EWMA2war1: EWMA2 with random effect of war | 4:level, slope, war, deaths | Q, T | diag(c(0, 0, Q.war))	| diag(c(1, 1, 0, 0)) | 6:lnQ.lvl, lnQ.slope, lnQ.war, lnQ.deaths, lnQ.warDeaths, lnH
8 | EWMA2war2: EWMA2 with variance effect for war |	2:level, slope |	Q |	0 | diag(2) | 5:lnQ.lvl, lnQ.slope, lnQ_war, lnQ_deaths, lnH

# 1a.  Estimate the Bayesian EWMA 

[KFAS](https://rweb.crmda.ku.edu/cran/web/packages/KFAS/KFAS.pdf) modeling begins with a [formula](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) that is converted to an "SSModel" object using the [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) function.  This is passed to [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) to estimate unknown parameters to maximize [logLik.SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/logLik.SSModel.html).  Confidence and prediction intervals can be obtained using [predict.SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/predict.SSModel.html).  Function [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html) will produce filtered and smoothed estimates of the state vector in components "a" and "alphahat", respectively, of an object of class "KFS":

<center> 
[formula](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) -> [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) -> [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html)  
</center>

Let's write a suitable formula for our Bayesian EWMA:

```{r}
suppressMessages(library(KFAS))
EWMA1fmla <- log(realGDPperCapita)~
  SSMtrend(1,Q=list(matrix(NA)), a1=log(realGDPperCapita[1]) )
```

This is converted to an SSModel as follows:  

```{r}
EWMA1mdl <-SSModel(EWMA1fmla, GDP, H=matrix(NA) )
```

This model has 2 unknowns, the NA's in EWMA1fmla and SSModel: 

  * Q = the state migration variance  
  
  * H = observation error variance.  

The default behavior of [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) is to estimate the logarithms of these two variance.  [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) requires us to provide starting values for log(Q) and log(H), in that order:  

```{r}
EWMA1fit <- fitSSM(EWMA1mdl, inits=c(lnQ=0, lnH=0))
```

Let's compute one-step ahead predictions with prediction intervals using [predict.SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/predict.SSModel.html):

```{r}
EWMA1pred <- predict(EWMA1fit$model, 
              interval='prediction', filtered=TRUE)
```

Let's plot these predictions:  

```{r,fig.cap = "EWMA1"}
plotPresWars(realGDPperCapita/1000, GDP, log='y', 
             main="EWMA fit", 
             ylab='thousands of 2009 dollars', las=1, 
             type='n', xlab='Year')
text(GDP$realGDPperCapita/1000, 'x', cex=0.5)
matlines(GDP$Year, exp(EWMA1pred)/1000, 
         col=c('blue', 'darkgreen', 'darkgreen'), 
         lty=c(1, 2, 2))
```

The one-step ahead prediction error and limits are so small it's hard to see what's going on in the range of this plot.  To study model deficiencies, etc., we need to look elsewhere.  For the moment, however, it's comforting to see such close agreement between the data and the 95 percent one-step ahead prediction limits.   

Next, let's consider log(likelihood) as a measure of goodness of fit. Unfortunately, there are two standard likelihoods commonly used for time series programmed into KFAS:  diffuse and marginal.  By default, the [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) function maximizes the diffuse likelihood, because it's faster to compute and is optimized with the same parameter values in many cases.  

In particular, if $Z_t$ or $T_t$ are functions of the unknown parameters, the diffuse and marginal likelihoods may not be optimized with the same parameter values;  see [logLik.SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/logLik.SSModel.html).  In such cases, the marginal likelihood should be used.  

In the examples considered here, neither $Z_t$ nor $T_t$ vary with unknown parameters.  However, we still need the marginal likelihood, because it will often not change between two different formulations of the same model, and the diffuse likelihood is more likely to change.  Thus, with nested models, the marginal likelihood should never be less for the larger model, but the diffuse likelihood might be.  We will see that later.  

For now, let's check this claim by maximizing the marginal likelihood:  

```{r}
EWMA1fitM <- fitSSM(EWMA1mdl, inits=EWMA1fit$optim.out$par, 
                    marginal=TRUE)
EWMA1fit$optim.out$par
EWMA1fitM$optim.out$par
logLik(EWMA1fit$model)
logLik(EWMA1fitM$model, marginal=TRUE)
```

As expected:  The log(likelihoods) are different, but they are maximized with the same parameter values.  

`r Citet(bib2, "KFASarticle")` notes that the diffuse log-likelihood can be written as follows:  

\begin{equation*}
\begin{aligned}
\log L_d  &= -\frac{1}{2}\sum^{n}_{t=1}\sum^{p_t}_{i=1}w_{i,t},
\end{aligned}
\end{equation*}

where

\begin{equation*}
w_{i,t} = \left\{ \begin{array}{ll}
\log F_{\infty,i,t}, &\mbox{if $F_{\infty,i,t}>0$,} \\
I(F_{i,t}>0)(\log2\pi + \log F_{i,t} + v^2_{i,t}F_{i,t}^{-1}), &\mbox{if $F_{\infty,i,t}=0$}, 
\end{array} \right.
\end{equation*}

and $F_{\infty,i,t}>0$, $v^2_{i,t}$, and $F_{i,t}$ are components of the list output by [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html). Thus, we can manually compute the diffuse log likelihood as follows:

```{r}
EWMA1.KFS <- KFS(EWMA1fit$model)
nInf <- length(EWMA1.KFS$Finf)
N <- nrow(EWMA1.KFS$model$y)
i. <- (nInf+1):N
-0.5*with(EWMA1.KFS, sum(log(Finf)) + (N-nInf)*log(2*pi) +
            sum(log(F[i.]) + v[i.]^2/F[i.]) )
```

The marginal likelihood is harder to compute, and we'll skip it for now.  

We'd also like to compute the [one-step ahead root mean square prediction error (rmse)](https://en.wikipedia.org/wiki/Root-mean-square_deviation).  These prediction errors are available as component "v" of the ouput from [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html):  

```{r}
sqrt(mean(EWMA1.KFS$v^2))
```

As noted above, log(1+x) is approximately x when x is small.  Therefore, we can interpret this as saying that sqrt(mean(EWMA1.v^2)) = 0.046 indicates a root mean square prediction error of approximately 4.6 percent.

Let's wrap these three goodness-of-fit measures in a fuction with the number of parameters estimated, so we can easily compute a 4-number summary for subsequent model comparison:

```{r}
logLik2 <- function(object, ...){
  ll2 <- rep(NA, 4)
  names(ll2) <- c('pars', 'diffuse', 'marginal', 'rmse')
  ll2[1] <- length(object$optim.out$par)
  ll2[2] <- logLik(object$model)
  ll2[3] <- logLik(object$model, marginal=TRUE)
  K. <- KFS(object$model)
  ll2[4] <- sqrt(mean(K.$v^2))
#
  ll2
}
```

Let's create a [data.frame](https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html) to store these numbers for the different models we'll fit:  

```{r}
mdls <- c('EWMA1', 'EWMA2', 'EWMA2pres1', 'EWMA2pres2', 
          'EWMA2pres3', 'EWMA2war0', 'EWMA2war1', 'EWMA2war2')
n.mdls <- length(mdls)
logLiks <- data.frame(npars=rep(NA, n.mdls), 
      diffuse=rep(NA, n.mdls), marginal=rep(NA, n.mdls), 
      rmse=rep(NA, n.mdls), row.names=mdls)
```

Let's look at and store this "logLik2" summary for this first model:

```{r}
logLiks[1, ] <- logLik2(EWMA1fit)
logLiks[1, ]
```

Beyond this, it is also interesting to look at the estimated migration and observation standard deviations:  

```{r}
exp(EWMA1fit$optim.out$par/2)
```

These estimates put the observation error at essentially zero.  It would be interesting to construct a confidence region for these two parameters, but we shall not attempt that here.  

It's good modeling practice to look at residuals.  For many purposes, standardized residuals are better than the raw residuals, because the standard deviation is officially known to be 1.  

Standardized residuals for the fit returned by [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) can be obtained using [rstandard.KFS](http://rpackages.ianhowson.com/cran/KFAS/man/rstandard.KFS.html):  

```{r}
EWMA1.rstd <- rstandard(EWMA1.KFS)
str(EWMA1.rstd)
```

With time series, it's good to look at the autocorrelation function of residuals:  

```{r,fig.cap = "Autocorrelation Function of Standardized Residuals"} 
(acf(EWMA1.rstd, na.action=na.pass))
(acf(EWMA1.rstd, na.action=na.pass, demean=FALSE))
```

If the model fit well, then the residuals should have zero mean.  The difference between the acfs with demean = TRUE (the default) and FALSE is a result of the obvious drift that creates an error in that assumption.  We expect this difference to disappear with a double EWMA considered in the next section.  

As another check, let's make a normal probability plot of these residuals to look for outliers:  

```{r,fig.cap = "Normal probability plot of Standardized Residuals"} 
qqnorm(EWMA1.rstd, datax=TRUE, 
       ylab='standardized residuals', 
       xlab='standard normal quantiles')
```

This looks like three line segments with different slopes.  This suggests a mixture of normals with the lowest and highest coming from component(s) with higher standard deviation.  It will be interesting to compare these plots with those of standardized residuals from other models.  

Before considering other models, however, let's plot these residuals vs. Presidents and wars:  

```{r,fig.cap = "EWMA residuals, Presidents and wars"}
plotPresWars(EWMA1.rstd, GDP, 
    yHoover=0.8, yFDR=.3, yWar=seq(.6, by=-.1, len=9), 
    ylab='one-step ahead prediction errors')
abline(h=0)
```

The biggest spikes all occur between 1900 and 1950.  Let's look closer at those:  

```{r,fig.cap = "EWMA residuals, Presidents and wars"}
plotPresWars(EWMA1.rstd, GDP, xlim=c(1900, 1950), 
    yHoover=0.8, yFDR=.3, yWar=seq(.6, by=-.1, len=9), 
    ylab='one-step ahead prediction errors')
abline(h=0)
```

We think we understand the spikes between 1929 and 1950.  Let's take a closer look at the 1908 spike:  

```{r,fig.cap = "EWMA residuals, Presidents and wars"}
plotPresWars(EWMA1.rstd, GDP, xlim=c(1900, 1910), 
    yHoover=0.8, yFDR=.3, yWar=seq(.6, by=-.1, len=9), 
    ylab='one-step ahead prediction errors')
abline(h=0)
```

Let's summarize what we get from these plots: 

  1.  During the Hoover administration, the economy performed consistently worse than this simple Bayesian EWMA predicted.  This is what we expected from earlier macroeconomic research, but it's nice to see it confirmed.  (It increases our confidence in the [KFAS](https://rweb.crmda.ku.edu/cran/web/packages/KFAS/KFAS.pdf) software.)
  
  1.  During the FDR years including WW II, the economy outperformed the EWMA predictions, except for the [Recession of 1937-38](https://en.wikipedia.org/wiki/Recession_of_1937%E2%80%9338).  (Again, this increases our confidence in the software.)  
  
  1.  We do NOT generally see that other wars are accompanied with large positive residuals, as we would expect if WW II and not FDR ended the Great Depression.  There were interesting spikes during the [Northwest Indian War](https://en.wikipedia.org/wiki/Northwest_Indian_War), the [U.S. Civil War](https://en.wikipedia.org/wiki/American_Civil_War), and the [Spanish](https://en.wikipedia.org/wiki/Spanish%E2%80%93American_War)-American-[Philippine](https://en.wikipedia.org/wiki/Philippine%E2%80%93American_War) war.  However, they were isolated and not obviously greater than other spikes that did not accompany wars.  
  
As one more check on this model, let's set the aberrant period 1929-1947 to NA and refit the model.  Let's first identify this most discrepant period:    

```{r}
depr1 <- with(GDP, (1927<=Year) & (Year <= 1948))
GDP[depr1, c('Year', 'realGDPperCapita')]
```

In spite of the [stock market crash that began on "black Thursday," Oct. 24, 1929](https://en.wikipedia.org/wiki/Wall_Street_Crash_of_1929), the average annual income in 1929 was almost 5 percent higher than in 1928.  Average annual income fell in 1930, so we'll start the exclusion period there.  We'll end the exclusion period in 1947, because the post-war recession ended then, as indicated by the fact that annual income in that year was less than in both 1946 and 1948:

```{r}
depr <- with(GDP, (1929<=Year)&(Year<=1947))
```

We can remove these years from any appropriate copy of realGDPperCapita and fit to that modified copy.  Conveniently, EWMA1mdl has such a copy in its first component, y:  

```{r}
names(EWMA1mdl)
EWMA1mdl.woDepr <- EWMA1mdl
EWMA1mdl.woDepr$y[depr] <- NA
EWMA1.woDeprFit<-fitSSM(EWMA1mdl.woDepr, 
                         inits=c(lnQ=0, lnH=0))
EWMA1.woDeprPred <- predict(EWMA1.woDeprFit$model, 
              interval='prediction', filtered=TRUE)
```

Now let's plot the predictions:  

```{r,fig.cap = "EWMA with 1929-1947 set to NA"}
plotPresWars(realGDPperCapita/1000, GDP, log='y', 
             main=paste0("EWMA fit\n", 
                         'without the Great Depression'), 
             ylab='thousands of 2009 dollars', las=1, 
             type='n', xlab='Year', xlim=c(1920, 1960), 
             ylim=c(5, 20), cex.main=1.1)
text(GDP$realGDPperCapita/1000, 'x', cex=0.5)
matlines(GDP$Year, exp(EWMA1.woDeprPred)/1000, 
         col=c('blue', 'darkgreen', 'darkgreen'), 
         lty=c(1, 2, 2))
```

The prediction is flat during the entire period set to NA, as we should expect from the model.  Moreover, 1948 is above the upper prediction limit.  This illustrates the need for something more, like a double EWMA.  This is a similar model that estimates both level and slope.  

# 2.  Double exponential smoothing:  More realistic but still not great for the Great Depression 

[Double exponential smoothing](https://en.wikipedia.org/wiki/Exponential_smoothing#Double_exponential_smoothing) runs an EWMA on the slope of a line and uses that in adjusting the level.  The standard Bayesian modification of that adjusts the weight on the last observation in proportion to the information content of the last observation relative to information accumulated in the previous estimate of the state, as suggested above.  As indicated in the table of models above, $\alpha_t$ has two components corresponding to the level and slope, and $Z_t$ is a row vector (1, 0).  This makes $y_t$ the estimated level plus noise.  $T_t$ is a 2 x 2 matrix with 0 in the lower left and 1's elsewhere, so the new level is the previous level plus the slope while the new slope is the previous slope, plus migration noise:  
  
$$T_t = \left[\begin{array}
{rrr}
1 & 1 \\
0 & 1 
\end{array}\right]
$$  

Similar to the simple EWMA considered above, $H_t$ is the observation variance.  By contrast, the state vector $\alpha_t$ is now 2-dimensional.  To manage this, we assume that $R_t$ is the 2-dimensional identity matrix, and $Q_t$ is a 2-dimensional diagonal matrix.  This gives us 3 parameters to estimate:  The two diagonal elements of the migration variance matrix $Q_t$ and the observation error variance $H_t$.  As before, by default, the algorithm estimates the logarithms of these parameters, which we will call lnQ.lvl, lnQ.slope, and lnH, as noted in the table above.

Modeling is a straightforward generalization of the above following the same process:

<center> 
[formula](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) -> [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) -> [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html)  
</center>

We start by supplying a formula using [SSMtrend(2, ...)](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html).  We select a starting value for $a_1$ with 0 slope, because that will make the EWMA1 discussed above a special case of this model (with zero migration variance for the slope).  That's important, because the [Neymanâ€“Pearson lemma](https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma) says that the most powerful test comparing two hypotheses is the likelihood ratio, and it helps to have one hypothesis nested within the other, e.g., when the "null hypothesis" is a special case of the "alternative".  Moreover, with most nested hypotheses [Wilks's theorem](https://en.wikipedia.org/wiki/Likelihood-ratio_test#Distribution:_Wilks.27s_theorem) says that twice the log(likelihood ratio) of nested hypotheses is approximately distributed as chi-square with degrees of freedom equal to number of parameters in the larger model fixed to create the smaller model.  

Unfortunately, Wilks's theorem does not apply when the null hypothesis is on a boundary, as with a variance parameter at 0.  In that case, the likelihood ratio is still most powerful, but twice the log(likelihood ratio) may not be approximately chi-square.  `r Citet(bib2, "PinBates")` recommend simulation to estimate p-values, but provide an example that suggests that 0.5 times the p-value for a chi-square(1) provides a reasonable approximation for the actual p-value when testing if a single variance parameter is zero;  we use this approximation below.  (They provide other examples that show that this simple rule does not generalize and adjusts in the wrong direction when eliminating fixed effects from a mixed model;  see their pp. 87-89.)

We construct the desired formula for the double EWMA as follows:  

```{r}
(a1.2 <- c(level=log(GDP$realGDPperCapita[1]), slope=0))
EWMA2fmla <- log(realGDPperCapita)~
  SSMtrend(2,Q=list(Q.lvl=matrix(NA), Q.slope=matrix(NA)), 
           a1=a1.2)
```

As above, we convert this to an [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html):  
```{r}
EWMA2mdl <-SSModel(EWMA2fmla, GDP, H=matrix(NA))
```

We pass this as with the simple EWMA to [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html): 

```{r}
EWMA2init <- c(lnQ.lvl=0, lnQ.slope=0, lnH=0)
EWMA2fit<-fitSSM(EWMA2mdl, inits=EWMA2init)
```

We pause here compute the 3 goodless of fit statistics discussed above:  

```{r}
logLiks[2, ] <- logLik2(EWMA2fit)
logLiks[1:2, ]
```

The RMSE at 0.043 is only slightly smaller than the root mean square prediction error of 0.046 for the standard Bayesian EWMA discussed above.  

Let's continue with twice the log(likelihood ratio):  

```{r}
(EWMAlogLik2.1 <- 2*diff(logLiks[1:2,2]))
```

Unfortunately, as discussed above, the assumptions for Wilks's theorem do not apply here.  The standard recommendation would be to compute a p-value for this using Monte Carlo.  Before going to that trouble, we first try the modification suggested by `r Citet(bib2, "PinBates")`, mentioned above:  

```{r}
0.5*pchisq(EWMAlogLik2.1, 1, lower=FALSE)
```

This gives us 6e-7.  Even if this is off by two or three orders of magnitude, the effect is still statistically significant -- as we would expect from the plots above.  

Let's continue as above by examining the estimated migration and observation error standard deviations:  

```{r}
exp(EWMA2fit$optim.out$par/2)
```

The migration standard deviation for the level is only slightly smaller that for the EWMA1 above.  The migration standard deviation for the slope and measurement noise seem much smaller than we might have expected.  It would be interesting to compute a 95 percent confidence interval on the standard deviation of the slope migration;  we will not attempt that here.  (The preferred approach, as previously indicated, would be Monte Carlo.)  

Next, we call [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html):

```{r}
EWMA2.KFS <- KFS(EWMA2fit$model)
```

To help us understand this model, we plot the smoothed estimates of the state vector over time:  

```{r,fig.cap = "Estimated level and slope of GDP"}
plotPresWars(EWMA2.KFS$alphahat, GDP, yHoover=0.38, 
             yFDR=0.55, yWar=seq(.48, by=-.05, len=9), 
             main=paste0('Double EWMA fit\n', 
                        'to USGDP per capita'), 
             cex.main=1.1)
```

The slope has the shape we expected from the plot, but it does not seem to fit the Hoover and FDR years well.  Because of the poor labeling of the vertical axis, let's compute the ranges of the smoothed state estimates:  

```{r}
apply(EWMA2.KFS$alphahat, 2, range)
```

The estimated slope is surprisingly constant, ranging only from 0.01704459 to 0.01704460.  That's much stiffer than might have been expected from other analyses that suggest that the growth in the early nineteenth century was less than in the late twentieth.  To check this, we'll plot 20-year running averages of the growth:

```{r,fig.cap = "20-year running averages of the growth rate"}
avgGrowth20 <- caTools::runmean(
        diff(log(GDP$realGDPperCapita)), 20)
plotPresWars(Year[-1], avgGrowth20, Data=GDP, type='l', 
             yFDR=0.2, las=1, xlab='Year', 
             ylab='20-year avg annual % growth', 
             main=paste0('Smoothed avg growth\n',
                    'in annual income per capita'), 
             yWar=seq(.8, by=-.1, len=9))
abline(h=c(0, .02, .04))
```

One might naively expect to see variability in alphahat[, 'slope'] closer to what we see in this plot.  Evidently, the maximum likelihood smoothing window is closer to 200 years than 20.  

We see two possible explanations for this surprising stiffness:  

  1. The algorithm missed the global maximum of the likelihood function.  
  1. The data may be artificially smooth.  
  
To check the first, we could make contour plots of the log(likehood) surface in a sufficiently broad region for the smallest two estimated parameters, lnQ.slope and lnH, as discussed, e.g., with the help page for [plot.profile.nls](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/plot.profile.nls.html) and in the [lme4 vignette](https://cran.rstudio.com/web/packages/lme4/vignettes/lmer.pdf) `r AutoCite(bib2, "lme4vignette")` and see how the above plot of alphahat[, 'slope'] would change when increasing lnQ.slope to its upper 80 percent confidence limit.  We shall not pursue that here.  

The second explanation seems plausible, in part because many time series are often adjusted after they are initially published.  We could check the literature on that or ask an expert.  

Let's look at the standardized residuals as before:  

```{r}
EWMA2.rstd <- rstandard(EWMA2.KFS)
str(EWMA2.rstd)
```

As before, let's look at the autocorrelation function of the residuals:  

```{r,fig.cap = "Autocorrelation Function of Standardized Residuals"} 
(acf(EWMA2.rstd, na.action=na.pass))
(acf(EWMA2.rstd, na.action=na.pass, demean=FALSE))
```

The difference between the acfs with demean = TRUE and FALSE has disappeared, as expected.  However, htere is still a lag one autocorrelation of 0.3.  We can hope to see that reduced in better fitting models.  

As another check, let's make a normal probability plot of these residuals to look for outliers:  

```{r,fig.cap = "Autocorrelation Function of Standardized Residuals"} 
qqnorm(EWMA2.rstd, datax=TRUE, 
       ylab='standardized residuals', 
       xlab='standard normal quantiles')
```

This looks quite similar to the comparable plot for EWMA1.  

As another evaluation of the fit during the FDR years, let's plot the one-step ahead prediction errors as before:  

```{r,fig.cap = "Double EWMA, Presidents and wars"}
plotPresWars(EWMA2.KFS$v, GDP, type='l', 
     main='Double EWMA\nprediction errors', 
     ylab='log(2009 dollars)', 
     yHoover=.8, yFDR=0.1, 
             yWar=seq(.7, by=-.12, len=9))   
abline(h=0)
```

Before proceeding with the next model, let's repeat the analysis with the Great Depression set to NA:  

```{r,fig.cap = "Double EWMA with 1929-1947 set to NA"}
EWMA2mdl.woDepr <- EWMA2mdl
EWMA2mdl.woDepr$y[depr] <- NA
EWMA2.woDeprFit<-fitSSM(EWMA2mdl.woDepr, inits=EWMA2init)
EWMA2.woDeprPred <- predict(EWMA2.woDeprFit$model, 
              interval='prediction', filtered=TRUE)
plotPresWars(realGDPperCapita/1000, GDP, log='y', 
             main=paste0('Double EWMA fit\n', 
                         'without the Great Depression'), 
             ylab='thousands of 2009 dollars', las=1, 
             type='n', xlab='Year', xlim=c(1920, 1960), 
             ylim=c(5, 20), cex.main=1.1) 
text(GDP$realGDPperCapita/1000, 'x', cex=0.5)
matlines(GDP$Year, exp(EWMA2.woDeprPred)/1000, 
         col=c('blue', 'darkgreen', 'darkgreen'), 
         lty=c(1, 2, 2))
```

The predictions are better than the standard EWMA, but the prediction limits are still too tight:  Most of Hoover's presidency is below the lower prediction limit.  FDR started below the lower limit and ended above the upper limit.  Clearly this period cannot be described by the model fit to the rest of the data.  

Let's look at the growth numbers for this period:  

```{r}
sel27.49 <- (GDP$Year %in% 1927:1949)
cbind(1928:1949, diff(EWMA2.woDeprPred[sel27.49,'fit']))
```

Without the data for 1930 to 1948, the model predicts an increase of almost 1.5 percent per year (exp(0.01456)-1 = 1.467 percent) for each year with no data, then a jump of 0.236 in 1949 to close the gap created by the faster-than-average growth during the FDR years, even ignoring the depth of the depression in the year that Hoover left office.  

Overall, this is a clear improvement over the standard EWMA discussed above.

Let's see if we can do better adding a random effect for presidents.  We consider five different ways to do this, as outlined in the table above.   

# 3.  Allowing the slope to change only between executives 

A simple presidential effect model is to assume that the slope is constant within each presidency but can change between administrations.  This uses the same state transition equation as the double EWMA just discussed, but the migration variance is zero except for the last year of each presidency:  That allows the slope to jump for the first year of the next presidency.  

This model can be estimated using [KFAS](https://rweb.crmda.ku.edu/cran/web/packages/KFAS/KFAS.pdf) but requires using a state transition variance, Q, that is not constant.  To fit this, we must write a special "updatefn" for [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html), because the default "updatefn" will not handle a time varying Q:  

<center> 
[(make the migration variance, Q, time varying)](http://rpackages.ianhowson.com/cran/KFAS/man/KFAS.html) -> [formula](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) -> [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) 

-> [(create updatefn)](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html)  
</center>

The state transition variance, Q, is typically specified as a list in [SSMtrend](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html).  Before changing this, let's first look at the structure of EWMA2mdl:  

```{r}
str(EWMA2mdl)
```

The most important thing to note for present purposes is that the component Q is "num [1:2, 1:2, 1] NA 0 0 NA":

```{r}
EWMA2mdl$Q
```

This was specified above as "Q=list(Q.lvl=matrix(NA), Q.slope=matrix(NA))" in the call above to [SSMtrend](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) that created EWMA2fmla.  We will change that here by replacing "Q.slope=matrix(NA)" with a three-dimensional array of all zeros except for making the slope component NA for the last year of each administration:  

```{r}
EWMA2pres1Q.slope <- array(0, c(1,1,N), 
      dimnames=list('slope', 'slope', GDP$Year))
contin <- duplicated(GDP$executive)
presLastYr <- c(!contin[-1], FALSE)
EWMA2pres1Q.slope[,,presLastYr] <- NA 
```

We now create a formula for this model:  

```{r}
EWMA2pres1fmla <- log(realGDPperCapita) ~ 
  SSMtrend(2, Q = list(lnQ.lvl=matrix(NA), 
                       lnQ.slope=EWMA2pres1Q.slope), a1=a1.2) 
```

As before, we use this to build an [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html): 

```{r}
EWMA2pres1mdl <-SSModel(EWMA2pres1fmla, GDP, H=matrix(NA))
```

The next step is to create the desired updatefn assuming we estimate three log(variance) parameters for lnQ.lvl, lnQ.slope, and lnH, as for the double EWMA above:    

```{r}
EWMA2pres1updt <- function(pars=EWMA2init, model=EWMA2pres1mdl, 
                           ...){
  vars <- exp(pars)
  Q <- model$Q
  Q[1,1,] <- vars[1]
  Q[2,2,presLastYr] <- vars[2]
  model$Q <- Q
  model$H[] <- vars[3]
  model
} 
```

We're now ready to call [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html): 

```{r}
EWMA2pres1fit <- fitSSM(EWMA2pres1mdl, inits=EWMA2init, 
                        updatefn=EWMA2pres1updt)
logLiks[3, ] <- logLik2(EWMA2pres1fit)
logLiks[1:3, ]
```

Both log(likelihoods) and the rmse are identical to those numbers for the double EWMA above (at least to the number of digits displayed here).  

As before, we'll compute and plot the smoothed estimate of the state vector:  

```{r,fig.cap = "Estimated level and slope of GDP for first President model"}
EWMA2pres1.KFS <- KFS(EWMA2pres1fit$model)
plotPresWars(EWMA2pres1.KFS$alphahat, GDP, yHoover=0.38, 
             yFDR=0.59, yWar=seq(.48, by=-.05, len=9), 
             main=paste0('Smoothed level and slope\n', 
                          'for first President model'), 
             cex.main=1.1)  
```

This is very similar to the double EWMA but with the slope held constant within administration -- precisely what we attempted to fit.  

However, since the model seems not to improve upon the double EWMA, we will leave this here and try the second President model mentioned above.  

# 4.  Assuming no continuity in slope between executives 

Another approach to modeling a president effect is to restart the slope from an overall average at the beginning of each presidency. We will do this by adding a third component to the state vector, giving it zero migration variance, and modifying the state transition matrix and migration variance accordingly.    

We'll use a state transition matrix as follows:  

$$T_t = \left[\begin{array}
{rrr}
1 & 1 & 0 \\
0 & \gamma_t & (1-\gamma_t) \\
0 & 0 & 1 
\end{array}\right], 
$$  

where $\gamma_t$ = 0 for the last year of a presidency, and 1 otherwise.  And $Q_t$ is as follows:  


$$Q_t = \left[\begin{array}
{rrr}
q_{\mathrm{lvl}} & 0 & 0 \\
0 & q_{\mathrm{pres2}} (1-\gamma_t) & 0 \\
0 & 0 & 0 
\end{array}\right], 
$$  

where $q_{\mathrm{lvl}}$ is the migration variance for the level, and $q_{\mathrm{pres2}}$ = $P_{1,2,2}$ is the variance of the presidential effect;  $P_{1,3,3}$ must be 0, matching $Q_{3,3,t}$ for all $t$.  And $P_{1,\infty}$ is a diagonal matrix with 1 in the first position and zeros elswhere to indicate a diffuse prior for the level but not the slope.  

This makes $\alpha_{2,t+1} = \alpha_{3,t} + \eta_t$ for $t$ = the last year of each presidency (and $t+1$ = the first year of the next).  For continuing years of a presidency, $\alpha_{2,t+1} = \alpha_{2,t}$, because $Q_{2,2,t}$ = 0 for those years.  

And making $Q_{3,3,t}$ = 0 for all $t$ means that $\alpha_{3,t}$ is normal with mean $a_{1,3}$ and the indicated presidential effect variance, $q_{\mathrm{pres2}}$.    

We'll accomplish with the same process as for EWMA2pres1:  

<center> 
[(make the migration variance, Q, time varying)](http://rpackages.ianhowson.com/cran/KFAS/man/KFAS.html) -> [formula](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) -> [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) -> 

[(make the state transition matrix, T, time varying)](http://rpackages.ianhowson.com/cran/KFAS/man/KFAS.html) -> [(create updatefn)](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html)  
</center>

Similar to the EWMA2 above, we start by supplying a formula using [SSMtrend(3, ...)](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) -- specifying the degree of the "trend" as 3 to give us a 3-dimensional state vector.  We want to estimate $a_{1,\mathrm{pres2}}$ = $a_{1,2}$ = $a_{1,3}$.  KFAS protocol assigns NA to numbers to be estimated.  And we can use the same Q.slope as with EWMA2pres1:      

```{r}
(a1.3 <- c(level=log(GDP$realGDPperCapita[1]), 
           slope=NA, a1.slope=NA))
EWMA2pres2.P1inf <- diag(c(1,0,0))
dimnames(EWMA2pres2.P1inf) <- list(names(a1.3), names(a1.3))
EWMA2pres2.P1 <- EWMA2pres2.P1inf
EWMA2pres2.P1[1,1] <- 0
EWMA2pres2.P1[2,2] <- NA
EWMA2pres2fmla <- log(realGDPperCapita)~
  SSMtrend(3,Q=list(Q.lvl=matrix(NA), Q.slope=EWMA2pres1Q.slope, 
                    Q.a1.slope=matrix(0)), 
           a1=a1.3, P1=EWMA2pres2.P1, P1inf = EWMA2pres2.P1inf)
```

We now use this to build an [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html):

```{r}
EWMA2pres2mdl. <-SSModel(EWMA2pres2fmla, GDP, H=matrix(NA))
```

[SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) does not remember the names of the states we assigned to a1.3 above. If we want those names to appear later, we can fix them now;  we'll write a function to do that:  

```{r}
fixModelNames <- function(model, stateNames){
  mdl <- model 
  mdlTime <- time(mdl$y)
# Z
  ynames <- dimnames(mdl$Z)[[1]]
  if(dim(mdl$Z)[3]>1){
    dimnames(mdl$Z) <- list(ynames, stateNames, 
                            mdlTime)
  } else {
    dimnames(mdl$Z) <- list(ynames, stateNames, NULL)
  }
# H
  if(dim(mdl$H)[3]>1){
    dimnames(mdl$H) <- list(ynames, ynames, 
                            mdlTime)
  } else {
    dimnames(mdl$H) <- list(ynames, ynames, NULL)
  }
# T   
  if(dim(mdl$T)[3]>1){
    dimnames(mdl$T) <- list(stateNames, stateNames, 
                            mdlTime)
  } else {
    dimnames(mdl$T) <- list(stateNames, stateNames, NULL)
  }
# R  
  if(dim(mdl$R)[3]>1){
    dimnames(mdl$R) <- list(stateNames, stateNames, 
                            mdlTime)
  } else {
    dimnames(mdl$R) <- list(stateNames, stateNames, NULL)
  }
# Q  
  if(dim(mdl$Q)[3]>1){
    dimnames(mdl$Q) <- list(stateNames, stateNames, 
                            mdlTime)
  } else {
    dimnames(mdl$Q) <- list(stateNames, stateNames, NULL)
  }
# a1, P1, P1inf 
  dimnames(mdl$a1)[[1]] <- stateNames 
  dimnames(mdl$P1) <- list(stateNames, stateNames)
  dimnames(mdl$P1inf) <- list(stateNames, stateNames)
#
  mdl 
}
EWMA2pres2mdl <- fixModelNames(EWMA2pres2mdl., 
                              names(a1.3) )
```

Next, we modify this model to make T time varying as desired:   

```{r}
T3.other <- EWMA2pres2mdl$T
EWMA2pres2.T <- array(T3.other, c(3,3,N), 
      dimnames=dimnames(T3.other))
dimnames(EWMA2pres2.T)[[3]] <- GDP$Year
EWMA2pres2.T[2,2,presLastYr] <- 0
EWMA2pres2.T[2,3,] <- presLastYr
EWMA2pres2.T[,,1:8]
```

President Washington's last year was 1796, and $T_{1796}$ is different from the other years, as we wanted.  

```{r}
EWMA2pres2mdl$T <- EWMA2pres2.T
```

We're not quite done modifying this model:  As noted with [help('SSModel')](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html), we must set attribute 'tv' to reflect that both T and Q are time varying.  From "str(EWMA2mdl)" above, we see that attr(EWMA2mdl1, "tv")= int [1:5] 0 0 0 0 0, indicating a model in which none of Z, H, T, R, and Q are time varying.  This is different for EWMA2pres1mdl:  

```{r}
attr(EWMA2pres2mdl, 'tv')
```

This says that only Q is time varying.  We just made T time varying and must change this 'tv' attribute to make it official.  In the process, we will add names to make the structure easier to read:  

```{r}
attr(EWMA2pres2mdl, 'tv') <- c(Z=0L, H=0L, T=1L, R=0L, Q=1L)
```

Now let's talk about unknown parameters to estimate:  This model requires us to estimate one parameter more than EWMApres1:  $a_{1,\mathrm{pres2}}$ = $a_{1,2}$ = $a_{1,3}$:  What initial values should we use for these parameters?  We can set a1.2 to the average slope from EWMA2pres1fit:  

```{r}
(EWMA2pres2.a1.2 <- mean(EWMA2pres1.KFS$alphahat[,2]))
```

The other three parameters are crudely similar to the three paramters estimates for EWMA2pres1:

```{r}
EWMA2pres1fit$optim.out$par
exp(EWMA2pres1fit$optim.out$par/2)
```

Three variances were estimated on the log scale, so exponentiating half those numbers gives us the corresponding standard deviations.  The migration standard deviation for the level was just over 0.04.  The other two were much smaller.  Let's use the largest of the three as the starting value for all three:  

```{r}
EWMA2pres2init <- c(a1.2=EWMA2pres2.a1.2,
        EWMA2pres1fit$optim.out$par)
EWMA2pres2init[3:4] <- EWMA2pres2init[2]
EWMA2pres2init
```

Let's modify the previous updatefn to do what we want for this model:  

```{r}
EWMA2pres2updt <- function(pars=EWMA2pres2init, 
                      model=EWMA2pres2mdl, ...){
#  a1 
  model$a1[2:3] <- pars[1]
#  Q  
  vars <- exp(pars[-1])
  Q <- model$Q
  Q[1,1,] <- vars[1]
  Q[2,2,presLastYr] <- vars[2]
  model$Q <- Q
# P1 
  model$P1[2,2] <- vars[2]
# H   
  model$H[] <- vars[3]
  model
} 
```

We now fit this model as follows:  

```{r}
EWMA2pres2fit <- fitSSM(EWMA2pres2mdl, 
          inits=EWMA2pres2init, updatefn=EWMA2pres2updt) 
logLiks[4, ] <- logLik2(EWMA2pres2fit)
logLiks[1:4, ]
```

This has a much better fit, as indicated by the increase in the log(likelihoods) and reduction in rmse.    

We next compute and plot the smoothed estimate of the state vector, as before:  

```{r,fig.cap = "Estimated level and slope of GDP, decoupling the presidents"}
EWMA2pres2.KFS <- KFS(EWMA2pres2fit$model)
plotPresWars(EWMA2pres2.KFS$alphahat, GDP, 
             yHoover=0.72, yFDR=.3, yWar=seq(.6, by=-.08, len=9),
             main='Decoupled presidents')
```

The slope here shows substantially more variability.  Let's look at it more closely:  

```{r,fig.cap = "Estimated level and slope of GDP, decoupling the presidents"}
plotPresWars(EWMA2pres2.KFS$alphahat[, 'slope'], GDP, 
             yHoover=0.72, yFDR=.3, yWar=seq(.6, by=-.08, len=9), 
             ylab='slope')
abline(h=0)
```

This strongly suggests that the Hoover administration was a statistical outlier, while FDR (with World War II) may or may not have been.  To make it easier to compare administrations, let's write a function to extract the growth associated with each president and its variance:  

```{r}
stateByFactor <- function(object, state='slope', 
                          factor.=GDP$executive, cor.=1, 
                          conf=0.95, factorName='president'){
# object has has components alphahat and V, 
#    because it is assumed to be of class KFS   
# mean state 
  stateNames <- colnames(object$alphahat)
  if(is.null(stateNames)){
    stop('alphahat needs colnames; absent')
  } 
  ist <- which(colnames(object$alphahat) == state)
  if(length(ist) != 1){
    stop('state = ', state, ' not found in ', 
         'colnames(alphahat) = ', 
         paste(stateNames, collapse=', '))
  }
#
  meanState <- mean(object$alphahat[, state])
  facState <- tapply(object$alphahat[, state], 
                      factor., mean)
  nSt <- length(facState)
# If the correlations are all 1, the standard deviation 
# of an average is the average of the standard deviations.
  meanVar. <- tapply(object$V[ist,ist,], factor., mean)
  meanSD. <- tapply(sqrt(object$V[ist,ist,]), 
                      factor., mean)
  meanVar <- (1-cor.)*meanVar.+cor.*(meanSD.^2)
  meanSD <- sqrt(meanVar)
#
  tabfac <- table(factor.)
  t. <- (facState-meanState)/meanSD 
  p. <- 2*pnorm(-abs(t.))
# variance estimated using all the data, 
# not just those within each presidency, 
# so dft = (total obs) - nSt
  dfe <- (nrow(object$alphahat) - nSt)
  st2 <- qt(1-.5*(1-conf), dfe) * meanSD
  st2. <- st2 %o% c(lower=-1, upper=1)
  confInt <- as.numeric(facState) + st2.
#
  Exec <- ordered(names(facState), names(facState))
  stateSum <- cbind(data.frame(Exec=Exec, 
          n=as.numeric(tabfac), mean=as.numeric(facState), 
          stdError=as.numeric(meanSD), t.=as.numeric(t.), 
          p_value=as.numeric(p.)), confInt)
  names(stateSum)[c(1, 3)] <- c(factorName, state)
# 
  chisq. <- sum(t.^2)
  F.. <- (chisq./(nSt-1))
  F. <- c(F=F.., df1=nSt-1, df2=dfe, 
          p=pf(chisq., nSt, dfe, lower=FALSE))
  print(F.)
  attr(stateSum, 'F') <- F.
#
  stateSum
}

(EWMA2pres2sum <- stateByFactor(EWMA2pres2.KFS))
```

The smallest p_value here is 1.3e-6 = 1.3 chances in a million for FDR.  [Bonferroni's rule](https://en.wikipedia.org/wiki/Bonferroni_correction) tells us to multiple the smallest p_value by the number of tests conducted, 41.  When we do that, we get 5e-5 = 5 chances in a hundred thousand. That's clearly statistically signficant.  The second smallest p_value is 1.5e-04 = 0.00015 for Hoover.  His administration is also clearly different from the rest of US economic history.  No one else seems different by these measures.  

As another check, we note that if the denominators for $k$ statistically independent student's $t$ statistics all have the same numbers of degrees of freedom, $n_1$, we can compute an F statistic by dividing their sum of squares by $k-1$:  We divide by $k-1$, because each $t$ is based on the difference of the economic growth during each administration and the overall average.  This means that the $k$ $t$ statistics are not statistically independent but rather have one linear dependency.  The denominator degrees of freedom is the number of degrees of freedom in estimate of variance used to compute the $t$'s.  That's the number of observations minus the number of presidents:  185 here.  The $F$ is modest, 1.46, but highly significant, because both numerator and denominator have relatively large numbers of degrees of freedom.   

Before we embrace this analysis, let's check how much the standard errors vary:  They are given by the "V" component of the output of  [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html) function:  

```{r,fig.cap = "Variance of the estimated slope, decoupling the presidents"}
plotPresWars(EWMA2pres2.KFS$V[2,2,]~Year, GDP, 
             yHoover=0.72, yFDR=.3, yWar=seq(.6, by=-.08, len=9), 
             type='l', ylab='smoothed slope variance')
```

This is plausibly constant within administration, which we would expect from specifying zero migration variance for the slope.  If this is correct, we would expect the "information" (i.e., reciprocal variance) to be proportional to the number of years in each presidency.  To confirm that, let's plot that:  

```{r,fig.cap = "Slope, variance, and number of years for each presidency"}
plot((1/stdError^2)~n, EWMA2pres2sum, 
     xlab='Number of years', ylab='info = 1/(smoothed variance)')
```

This looks like a straight line except for one point.  Who is that point?  

```{r,fig.cap = "Posterior variance vs. number of years for each presidency, labeled"}
plot((1/stdError^2)~n, EWMA2pres2sum, 
     xlab='Number of years', ylab='info = 1/(smoothed variance)')
text((1/stdError^2)~n, EWMA2pres2sum, 1:41)
```

Of course:  The one off the line is 41, the last, whose estimate cannot be adjusted by reference to a successor.   

Let's plot the confidence intervals just computed using [ggplot](http://rpackages.ianhowson.com/cran/ggplot2/man/ggplot.html):    

```{r,fig.cap = "Decoupled slope for each presidency"}
suppressMessages(library(ggplot2))

ggplot(EWMA2pres2sum[c('president', 'slope', 'lower', 'upper')], 
       aes(x=president, y=slope)) + geom_point() +
    coord_cartesian(ylim = c(-0.08, 0.08)) + 
    geom_errorbar(ymin=EWMA2pres2sum$lower,
                  ymax=EWMA2pres2sum$upper) + 
    geom_hline(aes(yintercept=mean(slope),color="red")) # mean slope
```  

This clearly says that the Hoover and FDR administrations were different from all others, but it still doesn't say whether FDR himself was different or World War II created the difference.  Before considering that, let's continue with the other alternative presidency model.  

One more question:  What were the parameter estimates?  

```{r}
EWMA2pres2fit$optim.out$par
exp(EWMA2pres2fit$optim.out$par[1])
exp(EWMA2pres2fit$optim.out$par[-1]/2)
```

This says that the average growth rate is 1.6 percent per year, the standard deviations of the migration for level and slope are 0.038, respectively, and the standard deviation of the observation noise is tiny, 0.00004.  

Before looking at the next model, let's review the standardized residuals as before:  

```{r}
EWMA2pres2.rstd <- rstandard(EWMA2pres2.KFS)
str(EWMA2pres2.rstd)
```

With time series, it's good to look at the autocorrelation function of residuals:  

```{r,fig.cap = "Autocorrelation Function of Standardized Residuals"} 
(acf(EWMA2pres2.rstd, na.action=na.pass, demean=TRUE))
```

The lag 1 autocorrelation is now only 0.17, slightly more than approximate upper 95 percent confidence limit.  That suggests progress.  

Let's again look at a normal probability plot of these residuals:  

```{r,fig.cap = "Normal probability plot of Standardized Residuals"} 
qqnorm(EWMA2pres2.rstd, datax=TRUE, 
       ylab='standardized residuals', 
       xlab='standard normal quantiles')
```

This looks quite similar to the previous normal plots of residuals.

What do we get by modeling a president effect as an adjustment to the slope of an otherwise standard Bayesian double EWMA?

# 5.  EWMA2 with an adjustment for each president 

This model considers a 3-dimensional state vector:  level, slope and a Presidential adjustment for slope.  For this, we will want a state transition matrix like the following:  

$$T_t = \left[\begin{array}
{rrr}
1 & 1 & 1 \\
0 & 1 & 0 \\
0 & 0 & \gamma_t 
\end{array}\right],
$$ 

where $\gamma_t$ = 0 for the last year of a presidency, and 1 otherwise, as with the immediately preceding model, EWMA2pres2.  

We combine this with migration variance $Q_t$ as follows:  

$$Q_t = \left[\begin{array}
{rrr}
q_{\mathrm{lvl}} & 0 & 0 \\
0 & q_{\mathrm{slope}} & 0 \\
0 & 0 & q_{\mathrm{pres3}} (1-\gamma_t) \\
\end{array}\right], 
$$  

where $q_{\mathrm{lvl}}$ is the migration variance for the level (as before), $q_{\mathrm{slope}}$ is the migration variance of the slope, $q_{\mathrm{pres3}}$ = $P_{1,3,3}$ is the variance of the presidential effect.  The rest of $P_1$ is 0, and $P_{1,\infty}$ is a diagonal matrix with elements (1, 1, 0) indicating a diffuse prior for level and slope but not the presidential effect, which we estimate.  

We will create this by modifying a triple EWMA following a process similar to the above:  

<center> 
[(make the migration variance, Q, time varying)](http://rpackages.ianhowson.com/cran/KFAS/man/KFAS.html) -> [formula](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) -> [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) -> 

[(make the state transition matrix, T, time varying)](http://rpackages.ianhowson.com/cran/KFAS/man/KFAS.html) -> [(create updatefn)](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html)  
</center>

Let's start by modifying the formula, similar to what we did with EWMA2pres1fmla, above, but for this 3-dimensional state    

```{r}
a1.3a <- c(level=log(GDP$realGDPperCapita[1]), slope=0, 
           pres3=0)
EWMA2pres3P1 <- diag(c(0, 0, NA))
EWMA2pres3P1inf <- diag(c(1, 1, 0))
EWMA2pres3fmla <- log(realGDPperCapita) ~ 
  SSMtrend(3, Q = list(level=matrix(NA), slope=matrix(NA),
                   pres3=EWMA2pres1Q.slope), 
      P1=EWMA2pres3P1, P1inf=EWMA2pres3P1inf, a1=a1.3a) 
```

We next create an [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html), as before:   

```{r}
EWMA2pres3mdl. <- SSModel(EWMA2pres3fmla, GDP, H=matrix(NA))
EWMA2pres3mdl <- fixModelNames(EWMA2pres3mdl., 
                              names(a1.3a) )
```

Now we need to create the desired time-varying state transition matrix, T:  

```{r}
pres3states <- names(a1.3a)
pres3T <- array(EWMA2pres3mdl$T, dim=c(3,3,N), 
        dimnames=list(pres3states, pres3states, GDP$Year) )
pres3T[1,3,] <- 1
pres3T[2,3,] <- 0 
pres3T[3,3, presLastYr] <- 0
pres3T[,,1:9]

EWMA2pres3mdl$T <- pres3T 
```

As for EWMA2pres2mdl, we need also to fix the 'tv' attribute:  

```{r}
attr(EWMA2pres3mdl, 'tv') <- c(Z=0L, H=0L, T=1L, R=0L, Q=1L)
```

We now have 4 parameters to estimate:  lnQ.lvl, lnQ.slope, lnQ.pres3, and lnH.  As for EWMA2pres2, we select starting values for the parameters based on the previous fit:  

```{r}
EWMA2pres2fit$optim.out$par
EWMA2pres3init <- rep(EWMA2pres2fit$optim.out$par[2], 4)
names(EWMA2pres3init) <- c("lnQ.lvl", "lnQ.slope", 
        "lnQ.pres3", "lnH")
EWMA2pres3init
```

This different model requires a different 'updatefn':   

```{r}
EWMA2pres3updt <- function(pars=EWMA2pres3init, 
                      model=EWMA2pres3mdl, ...){
  vars <- exp(pars)
  Q <- model$Q
  Q[1,1,] <- vars[1]
  Q[2,2,] <- vars[2]
  Q[3,3,presLastYr] <- vars[3]
  model$Q <- Q
  model$P1[3,3] <- vars[3]
  model$H[] <- vars[4]
  model
}

EWMA2pres3fit <- fitSSM(EWMA2pres3mdl, inits=EWMA2pres3init, 
                        updatefn=EWMA2pres3updt) 
logLiks[5, ] <- logLik2(EWMA2pres3fit)
logLiks[1:5, ]
```

The diffuse likelihood and the root mean square error are worse for EWMApres3 than for EWMApres2, but the marginal likelihood is better. The theory says we should trust the marginal likelihood.  However, the root mean square of the one-step ahead prediction errors is worse with the better marginal likelihood.  

Let's compute the smoothed state vectors as before:  

```{r,fig.cap = "Estimated level and slope of GDP plus an adjustment for each president"}
EWMA2pres3.KFS <- KFS(EWMA2pres3fit$model)
plotPresWars(EWMA2pres3.KFS$alphahat, GDP, 
             yHoover=0.72, yFDR=.3, yWar=seq(.6, by=-.08, len=9),
             main='Decoupled presidents')
```

This is interesting:  Let's check the parameter estimates and the ranges of of the three components of the state vector:  

```{r}
EWMA2pres3fit$optim.out$par
exp(EWMA2pres3fit$optim.out$par/2)
apply(EWMA2pres3.KFS$alphahat, 2, range)
```

The slope is estimated as a constant, making this model virtually equivalent to EWMA2pres2.  

What does the presidential summary look like? 

```{r}
(EWMA2pres3sum <- stateByFactor(EWMA2pres3.KFS, "pres3"))
```

This seems quite similar to the EWMA2pres2 model.  Let's plot this summary as before:  

```{r,fig.cap = "EWMA2pres3 slope for each presidency"}
ggplot(EWMA2pres3sum[c('president', 'pres3', 'lower', 'upper')], 
       aes(x=president, y=pres3)) + geom_point() +
    coord_cartesian(ylim = c(-0.08, 0.08)) + 
    geom_errorbar(ymin=EWMA2pres3sum$lower,
                  ymax=EWMA2pres3sum$upper) + 
    geom_hline(aes(yintercept=mean(pres3),color="red")) 
```

This is quite similar to the corresponding plot for EWMA2pres2.  These two models support the same basic conclusion:  There is a president effect, the Hoover administration performed distinctly worse than the others and the FDR administration performed distinctly better.  

However, there are difference between the two that are not easy to understand or describe.  EWMA2pres3 has a better marginal likelihood but worse root mean square prediction error.  

Let's look at the standardized residuals as before:  

```{r,fig.cap = "Autocorrelation Function of Standardized Residuals from EWMA2pres3"} 
EWMA2pres3.rstd <- rstandard(EWMA2pres3.KFS)
str(EWMA2pres3.rstd)
(acf(EWMA2pres3.rstd, na.action=na.pass, demean=TRUE))
```

This is essentially the same as EWMA2pres2.  

Let's again look at a normal probability plot of these residuals:  

```{r,fig.cap = "Autocorrelation Function of Standardized Residuals"} 
qqnorm(EWMA2pres3.rstd, datax=TRUE, 
       ylab='standardized residuals', 
       xlab='standard normal quantiles')
```

As before.  The continued presence of the image of a mixture of normals suggests an opportunity to improve the fit through improving the noise term, e.g., with [Autoregressive conditional heteroskedasticity](https://en.wikipedia.org/wiki/Autoregressive_conditional_heteroskedasticity).  We will not pursue that here.  

NOTE:  An equivalent model estimating the same parameters could have a 43-dimensional state vector with components level, slope, and Pres1, ..., Pres41.  The memory and compute time required to fit it would be greater, but the [logLik](http://rpackages.ianhowson.com/cran/KFAS/man/logLik.SSModel.html) and parameter estimates should be the same.  This is unnecessary here but could be required with, e.g., an experiment with levels for a random effect that are not sequential in time.  

# 6.  EWMA2 with a fixed effect for war 

The plots discussed above suggest that if war has a macroeconomic effect, it increases the rate of economic growth.  This suggests we model the impact of war as an adjustment to slope for incrementing level within the state transition matrix, $T_t$.  It further suggests we want a four-dimensional state vector, with one component ($w_0$) for the presence ($w_0$ = 1) or absence ($w_0$ = 0) of war and the second proportional to battle deaths per million population ($w_1$):

$$T_t = \left[\begin{array}
{rrrr}
1 & 1 & w_0 & w_1 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 
\end{array}\right],
$$ 

For this model, Q is constant, and we want a diffuse prior on all 4 components of the initial state vector.  Thus, $P_{1,\infty}$ is the 4-dimensional identity matrix, and $P_1$ is the 4-dimensional zero matrix.  

Thus, for this model, we do not need to create a time-varying Q nor an updatefn as we did for models 3-5.  This simplifies the modeling process to the following:  

<center> 
[formula](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) -> [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) -> 

[(make the state transition matrix, T, time varying)](http://rpackages.ianhowson.com/cran/KFAS/man/KFAS.html) -> [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html)  
</center>

We can model war as a fixed effect multiple ways.  One is to use $R_t$ = the 4-dimensional identity matrix as before, with $Q_t$ being a diagonal matrix with only the first two elements nonzero.  Another is to let $R_t$ be the first two columns of a 4-dimensional identity matrix and estimate the diagonal of the resulting 2 x 2 $Q_t$ matrix.  We'll use the former here, because the next model with war as a random effect requires $R_t$ = the 4-dimensional identity matrix.  

We'll use a similar formula to those above, requesting a fourth degree [SSMtrend](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) and modifying $T_t$ as before:  

```{r}
a1.4 <- c(level=log(GDP$realGDPperCapita[1]), slope=0, 
           war=0, deaths=0)
EWMA2war0fmla <- log(realGDPperCapita) ~ 
    SSMtrend(4, Q = list(level=matrix(NA), slope=matrix(NA),
                  war=matrix(0), deaths=matrix(0)), a1=a1.4) 
EWMA2war0mdl. <- SSModel(EWMA2war0fmla, GDP, H=matrix(NA))
```

As before, let's fix the names of components of EWMAwar0mdl:  

```{r}
EWMA2war0mdl <- fixModelNames(EWMA2war0mdl., 
                       names(a1.4) )
```

Now we need to create the desired time-varying state transition matrix, $T_t$:  

```{r}
warStates <- names(a1.4)
war0T <- array(diag(4), dim=c(4,4,N), 
    dimnames=list(warStates, warStates, GDP$Year))
war0T[1, 2,] <- 1  
war0T[1, 3,] <- (GDP$war!='')
war0T[1, 4,] <- GDP$battleDeathsPMP
war0T[,,1:9]
```

Let's check this $T_t$ with years at war and peace.  

```{r}
GDP[c(1, 2, 7), c('Year', 'war', 'battleDeathsPMP')]
war0T[,,c(1, 2, 7)]
```

They match.  Let's save this T as part of EWMA2war0mdl:  

```{r}
EWMA2war0mdl$T <- war0T 
```

We also need to fix the 'tv' attribute, as we did for models 4 and 5 (EWMA2pres2 and EWMA2pres3):  

```{r}
attr(EWMA2war0mdl, 'tv') <- c(Z=0L, H=0L, T=1L, R=0L, Q=0L)
```

This model has the same 3 parameters to estimate as models 2, 3 and 4 above:  lnQ.lvl, lnQ.slope, and lnH.  We will use the same initial values:  EWMA2init.

```{r}
(EWMA2war0fit <- fitSSM(EWMA2war0mdl, inits=EWMA2init)) 
logLiks[6, ] <- logLik2(EWMA2war0fit)
logLiks[1:6, ]
```

Conclusion:  

  1.  If we use the marginal likelihood rather than the diffuse likelihood, it says that EWMA2war0 gives a slightly better fit than EWMA2:  396.9705 vs. 396.5067.  

  1.  However, the improvement in the fit is so slight, it's clearly not statistically significant.  

As a check on this model, we should get the same answer as from EWMA2 if we set the war components of P1inf to 0:  

```{r}
EWMA2war0mdl2 <- EWMA2war0mdl 
war0P1inf <- diag(c(1, 1, 0, 0))
dimnames(war0P1inf) <- list(warStates, warStates)
EWMA2war0mdl2$P1inf <- war0P1inf
EWMA2war0fit2 <- fitSSM(EWMA2war0mdl2, inits=EWMA2init)
logLik2(EWMA2war0fit2)
```

This gives the same [logLik](http://rpackages.ianhowson.com/cran/KFAS/man/logLik.SSModel.html) and rmse as EWMA2, as we expected.  Let's modify the modeling process to include an updatefn to allow us to estimate P1[3:4, 3:4] different from [diag(0, 2)](https://stat.ethz.ch/R-manual/R-devel/library/base/html/diag.html):  

<center> 
[formula](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) -> [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) -> [(make the state transition matrix, T, time varying)](http://rpackages.ianhowson.com/cran/KFAS/man/KFAS.html) 

[(create updatefn)](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html)  
</center>

P1[3:4, 3:4] is a 2 x 2 positive definite matrix.  A standard representation for such a matrix is provided by [nlme::pdLogChol](http://rpackages.ianhowson.com/cran/nlme/man/pdLogChol.html).  The pdLogChol representation of a symmetric positive definite matrix is a vector starting with the logarithms of the diagonal of the [Choleski factorization](https://stat.ethz.ch/R-manual/R-devel/library/base/html/chol.html) of that matrix followed by its [upper triangular portion](https://stat.ethz.ch/R-manual/R-devel/library/base/html/lower.tri.html).  To see this, consider the following simple example:  

```{r}
(pd4 <- nlme::pdLogChol(1:6))
(pd4C <- chol(pd4))
log(diag(pd4C))
pd4C[upper.tri(pd4C)]

(pd4c <- nlme::pdLogChol(-c(1,1,1, 4:6)))
(pd4cC <- chol(pd4c))
log(diag(pd4cC))
pd4cC[upper.tri(pd4cC)]
```

We want to use this in the updatefn.  This requires adding the three [nlme::pdLogChol](http://rpackages.ianhowson.com/cran/nlme/man/pdLogChol.html) paramters to the parameters to be estimated.  The first 3 of these 6 parameters are the logarithms of the Cholesky square root of the covariance matrix it represents.  Thus, the first parameter is the log of the standard deviation of the first variable.  The second is the log of the residual standard deviation of the second variable after its regression on the first is removed.  The third is similarly the log of the residual standard deviation of the third variable after its regression on the first two is removed.  The fourth is the regression coefficient of the second variable on the first after normalizing the first to standard deviation of one.  The fifth and sixth are similarly the regression coefficients of the third variable on the first and the residuals of the second from predictions based on the first, after normalization as before.  

```{r}
EWMA2war0init <- c(EWMA2fit$optim.out$par, 
                lnP1.33=0, lnP1.44=0, lnP1.34=0)
EWMA2war0updt <- function(pars=EWMA2war0init, 
                      model=EWMA2war0mdl2, ...){
  vars <- exp(pars[1:3])
  Q <- model$Q
  Q[1,1,] <- vars[1]
  Q[2,2,] <- vars[2]
  model$Q <- Q
  model$H[] <- vars[3]
  P1 <- nlme::pdLogChol(pars[4:6])
  model$P1[3:4, 3:4] <- as.matrix(P1)
  model
} 
EWMA2war0fit3 <- fitSSM(EWMA2war0mdl2, inits=EWMA2war0init, 
                        updatefn=EWMA2war0updt)
logLik2(EWMA2war0fit3)
```

This is worse than EWMA2war0fit and EWMA2war0fit2.  

However, time series models are known to occasionally have convergence problems and even multimodal likelihoods.  Therefore, let's check with starting values designed to give the same answer as EWMA2:  

```{r}
EWMA2war0init2 <- c(EWMA2fit$optim.out$par, 
                lnP1.33=-999, lnP1.44=-999, lnP1.34=0)
EWMA2war0fit4 <- fitSSM(EWMA2war0mdl2, inits=EWMA2war0init2, 
                        updatefn=EWMA2war0updt)
logLik2(EWMA2war0fit4)
```

This matches logLik(EWMA2war0fit2$model).  Let's try something between EWMA2war0init and EWMA2war0init2:  

```{r}
EWMA2war0init3 <- c(EWMA2fit$optim.out$par, 
                lnP1.33=-9, lnP1.44=-9, lnP1.34=0)
EWMA2war0fit5 <- fitSSM(EWMA2war0mdl2, inits=EWMA2war0init3,
                        updatefn=EWMA2war0updt)
logLik2(EWMA2war0fit5)
```

At logLik = 383.8239, this is not as good as EWMA2war0fit5.  We might get something better with different starting values.

```{r}
EWMA2war0init4 <- c(EWMA2fit$optim.out$par, 
                lnP1.33=-2, lnP1.44=-9, lnP1.34=0)
EWMA2war0fit6 <- fitSSM(EWMA2war0mdl2, inits=EWMA2war0init4, 
                        updatefn=EWMA2war0updt)
logLik2(EWMA2war0fit6)
```

Let's give up for the moment.  

# 7. EWMA2 with a random effect for war 

This model combines EWMA2pres3 with EWMA2war0.  We will use a time-varying state transition matrix as follows:    

$$T_t = \left[\begin{array}
{rrrr}
1 & 1 & w_0 & w_1 \\
0 & 1 & 0 & 0 \\
0 & 0 & \omega_t & 0 \\
0 & 0 & 0 & \omega_t  
\end{array}\right],
$$ 

where $\omega_t$ = 1 during wars and 0 otherwise.  And we need to make the migration variance time varying to match: 

<center> 
[(make the migration variance, Q, time varying)](http://rpackages.ianhowson.com/cran/KFAS/man/KFAS.html) -> [formula](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) -> [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) -> 

[(make the state transition matrix, T, time varying)](http://rpackages.ianhowson.com/cran/KFAS/man/KFAS.html) -> [(create updatefn)](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [fitSSM](http://rpackages.ianhowson.com/cran/KFAS/man/fitSSM.html) -> [KFS](http://rpackages.ianhowson.com/cran/KFAS/man/KFS.html)  
</center>

Similar to EWMA2pres2 and EWMA2pres3, we will allow Q for the (war, deaths) components of the state vector to be nonzero the year before the start of each war:   

```{r}
(beforeWar <- which(c(
      head(GDP$war, -1)=='' & tail(GDP$war, -1)!=''), FALSE))
```

Let's check:  

```{r}
GDP[beforeWar[1]+0:1,]
```

We want Q[1:2, 1:2, ] to be diag(c(NA, NA)), Q[3:4, 3:4, beforeWar] to NA;  all other elements of Q should be 0:  

```{r}
EWMA2warQ <- array(0, c(4,4,N), 
    dimnames=list(warStates, warStates, GDP$Year))
EWMA2warQ[1,1,] <- NA
EWMA2warQ[2,2,] <- NA
EWMA2warQ[3:4,3:4,beforeWar] <- NA 
```

Let's confirm we got what we intended:  

```{r}
EWMA2warQ[,,beforeWar[1]+(-1):1]
```

[SSMtrend(4, ...)](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) requires Q to be a list of length 4, so we can't use that. Instead, we'll copy the previous [SSModel](http://rpackages.ianhowson.com/cran/KFAS/man/SSModel.html) and modify Q directly:  

```{r}
EWMA2war1mdl <- EWMA2war0mdl
EWMA2war1mdl$Q <- EWMA2warQ
attr(EWMA2war1mdl, 'tv')[5] <- 1L
```

Since we are estimating P1[3:4, 3:4] = Q[3:4, 3:4, beforeWar], we need to set P1inf to diag(c(1,1,0,0)):  

```{r}
EWMA2war1mdl$P1inf <- diag(c(1,1,0,0))
```

We also want to set T[3:4, 3:4, GDP$war==''] to 0:    

```{r}
war1T <- war0T
war1T[3:4, 3:4, GDP$war==''] <- 0
war1T[,,c(1:2, 8, 22:24)]
```

Looks good.  Let's put it in the model:  

```{r}
EWMA2war1mdl$T <- war1T
```

We also need a matching updatefn.  That requires specifying the parameters to be estimated, for which we will ultimately need starting values.  For this, we'll want to include 3 parameters for the [nlme::pdLogChol](http://rpackages.ianhowson.com/cran/nlme/man/pdLogChol.html) representation of Q[3:4, 3:4].  We'll call these parameters lnQ.war, lnQ.deaths, and lnQ.warDeaths.  However, since the first two are more like standard deviations than variances, we'll adjust their starting values accordingly.  And the lnQ.warDeaths is more like a regression coefficient, and we'll start that at 0:  

```{r}
EWMA2war1init <- 
    c(1, 1, .5, .5, 0, 1)*rep(EWMA2fit$optim.out$par[1], 6)
names(EWMA2war1init) <- c('lnQ.lvl', 'lnQ.slope', 
      'lnQ.war', 'lnQ.deaths', 'lnQ.warDeaths', 'lnH')
EWMA2war1init
EWMA2war1updt <- function(pars=EWMA2war1init, 
                      model=EWMA2war1mdl, ...){
  vars <- exp(pars[c(1:2, 6)])
  Q <- model$Q
  Q[1,1,] <- vars[1]
  Q[2,2,] <- vars[2]
#  
  P1w <- as.matrix(nlme::pdLogChol(pars[3:5]))
  model$P1[3:4, 3:4] <- P1w
  Q[3:4, 3:4, beforeWar] <- P1w
  model$Q <- Q
#  
  model$H[] <- vars[3]
  model
} 
EWMA2war1fit <- fitSSM(EWMA2war1mdl, inits=EWMA2war1init, 
                        updatefn=EWMA2war1updt)
logLiks[7, ] <- logLik2(EWMA2war1fit)
logLiks[1:7, ]
```

This looks like more convergence problems with logLik numbers slightly less than those for EWMA2.  

Let's check to confirm we can get logLik(EWMA2fit[['model']]) as before:  

```{r}
EWMA2war1init0 <- EWMA2war1init
EWMA2war1init0[c(1, 2, 6)] <- EWMA2fit$optim.out$par
EWMA2war1init0[3:5] <- c(-999, -999, 0)
EWMA2war1fit0 <- fitSSM(EWMA2war1mdl, inits=EWMA2war1init0, 
                        updatefn=EWMA2war1updt)
logLik2(EWMA2war1fit0)
```

These match EWMA2.  Let's refit with different starting values:  

```{r}
EWMA2war1init1 <- EWMA2war1init
EWMA2war1init1[c(1, 2, 6)] <- EWMA2fit$optim.out$par
EWMA2war1init1[3:4] <- EWMA2fit$optim.out$par[1]/2
EWMA2war1fit0 <- fitSSM(EWMA2war1mdl, inits=EWMA2war1init0, 
                        updatefn=EWMA2war1updt)
logLik2(EWMA2war1fit0)
```

These also match EWMA2.  That suggests we may not be able to do better with this model.  

# 8. EWMA2 with variance effect for war

One more possibility is to allow for substantial, single-year changes in the level in EWMA2 by modeling log(Q[1,1]) ~ war + deaths.  For this, we start with EWMA2 and make Q time varying with an appropriate updatefn.  

```{r}
EWMA2war2mdl <- EWMA2mdl
EWMA2war2Q <- array(EWMA2mdl$Q, dim=c(2,2,N), 
    dimnames=list(names(a1.2), names(a1.2), GDP$Year))
EWMA2war2Q[,, 1:2]
```

This looks OK.  

```{r}
EWMA2war2mdl$Q <- EWMA2war2Q
attr(EWMA2war2mdl, 'tv') <- 
        c(Z=0L, H=0L, T=0L, R=0L, Q=1L)

EWMA2war2init <- c(1, 0, 0, 1, 1)* EWMA2fit$optim.out$par[1]
names(EWMA2war2init) <- c('lnQ.lvl', 'lnQ.lvl.war',
                'lnQ.lvl.deaths', 'lnQ.slope', 'lnH')
EWMA2war2init
```

This looks like plausible starting values.  

```{r}
EWMA2war2updt <- function(pars=EWMA2war2init, 
                      model=EWMA2war2mdl, ...){
#
  Q <- model$Q
  lnQ11 <- (pars[1] + pars[2]*(GDP$war!='') +
                   pars[3]*GDP$battleDeathsPMP)
  Q11 <- exp(lnQ11)
  oops <- which(!is.finite(Q11))
  Q11[oops] <- .Machine$double.xmax
#  
#  noops <- length(oops)
#  if(noops>0){
#    cat('Q[1,1] NA or Inf with pars =\n')
#    print(pars)
#    stop('Problem occurs ', noops, ' times, ', 
#         'starting with number ', noops[1], 
#         ' for which Q[1,1] = ', Q11[oops[1]])
#  }
  Q[1,1,] <- Q11
#
  Q22 <- exp(pars[4])
  if(!is.finite(Q22)){
    print(pars)
    stop('Q22 = ', Q22)
  }
  
  Q[2,2,] <- exp(pars[4])
  model$Q <- Q
#  
  model$H[] <- exp(pars[5])
  model
} 
EWMA2war2updt()

EWMA2war2fit <- fitSSM(EWMA2war2mdl, inits=EWMA2war2init, 
                        updatefn=EWMA2war2updt)
logLiks[8, ] <- logLik2(EWMA2war1fit)
logLiks[1:8, ]
```

This matches EWMA2war1.  

# Discussion 

The conclusions from the different models tested match the naive analysis that inspired this work:  

  1.  There has been a substantive difference in the performance of the economy between administrations, with no indication of any changes in the rate of improvement in average annual income apart from this administration effect.  
  1.  There is no evidence that any of the three formulations of a war effect can explain any part of the variability in average annual income (GDP per capita, adjusted for inflation) in U.S. economic history.  
  1.  The near-zero estimate for the observation error variance, H, and the migration variance for the slope in many models suggests that the numbers we have were already smoothed to reduce (artificially) the between-year variability.  
  1.  Some time series models are known to have multiple local maxima of the likelihood function for some data sets.  To check for this, it could help to make contour plots of the log(likehood) surface in a sufficiently broad region of the apparent optimum to identify other and perhaps better local optima;  such alternative optima would presumably be visible in plots of a moderately but not excessively broad region of the optimum identified by the standard algorithm.  Such plots could also display a joint confidence region for any interesting pair of parameters.  (We may also wish to use simuluation to calibrate the confidence regions for cases like many considered here where the assumptions of [Wilks's theorem](https://en.wikipedia.org/wiki/Likelihood-ratio_test#Distribution:_Wilks.27s_theorem) do not hold.) It could be interesting to reestimate some of these models with the migration variance for the slope fixed at, e.g., its upper 90th percentile.  This might reduce the variations between administration, but we'd be surprised if it changed the overall conclusions.  This is left for future work.  

# References
```{r results = "asis", echo = FALSE}
PrintBibliography(bib2)
```
